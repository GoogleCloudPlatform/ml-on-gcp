{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GCP AI Platform Object Detection Built-in Algorithm.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jys-gg/ml-on-gcp/blob/master/tutorials/builtin_algorithms/GCP_AI_Platform_Object_Detection_Built_in_Algorithm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "deletable": true,
        "editable": true,
        "id": "qnMpW5Y9nv2l",
        "colab": {}
      },
      "source": [
        "# Copyright 2019 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0OTCmRQgmbp",
        "colab_type": "text"
      },
      "source": [
        "# GCP AI Platform Built-in Algorithm: Image Object Detection\n",
        "\n",
        "In this tutorial we will train an object detection model (with TPU) and then deploy it to AI platform for prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dvc1ram3cnnh",
        "colab_type": "text"
      },
      "source": [
        "## Setting up Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOK96Jedv566",
        "colab_type": "text"
      },
      "source": [
        "### Set up your GCP project following the [instructions](https://cloud.google.com/ml-engine/docs/tensorflow/getting-started-training-prediction#setup):\n",
        "\n",
        "\n",
        "\n",
        "*   Select or create a GCP project.\n",
        "*   Make sure that billing is enabled for your Google Cloud Platform project.\n",
        "*   Enable the AI Platform (\"Cloud Machine Learning Engine\") and Compute Engine APIs. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d3Q73EeZc40G",
        "colab": {}
      },
      "source": [
        "!pip install google-cloud\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "humJz-nxwhJG",
        "colab": {}
      },
      "source": [
        "# Set the GCP project-id and region, and bucket.\n",
        "\n",
        "# Please use your own project_id.\n",
        "PROJECT_ID=''\n",
        "REGION='us-central1'\n",
        "\n",
        "!gcloud config set project {PROJECT_ID}\n",
        "!gcloud config set compute/region {REGION}\n",
        "\n",
        "# Create bucket (it is ok if the bucket has already been created)\n",
        "JOB_OUTPUT_BUCKET=\"gs://{}_image_detection\".format(PROJECT_ID)\n",
        "!echo $JOB_OUTPUT_BUCKET\n",
        "!gsutil mkdir -p $PROJECT_ID $JOB_OUTPUT_BUCKET"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRdaO7iRvzDi",
        "colab_type": "text"
      },
      "source": [
        "### Setup TPU for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCEtxgTsv4W2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "\n",
        "!curl -H \"Authorization: Bearer $(gcloud auth print-access-token)\"  \\\n",
        "    https://ml.googleapis.com/v1/projects/$PROJECT_ID:getConfig | cat > ./access_token.json\n",
        "    \n",
        "with open('access_token.json', 'r') as f:\n",
        "  TPU_SERVICE_ACCOUNT=json.load(f)['config']['tpuServiceAccount']    \n",
        "\n",
        "!echo \"Adding TPU service account for $TPU_SERVICE_ACCOUNT\"\n",
        "\n",
        "!gcloud projects add-iam-policy-binding $PROJECT_ID \\\n",
        "    --member serviceAccount:$TPU_SERVICE_ACCOUNT --role roles/ml.serviceAgent"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ksBs1CD3_cD",
        "colab_type": "text"
      },
      "source": [
        "## Submitting a training Job\n",
        "\n",
        "To submit a job we need to specify some basic training arguments and some basic arguments related to our algorithm.\n",
        "\n",
        "Let's start with setting up arguments and using gcloud to submit the Job.\n",
        "* Training Job arguments: `job_id, job-dir, scale-tier, master-image-uri, region`.\n",
        "* Algorithm Arguments: \n",
        "  *   `training_data_path`: Path to a TFRecord path pattern used for training.\n",
        "  *   `validation_data_path`: Path to a TFRecord path pattern used for validation.\n",
        "  *    `pretrained_checkpoint_path`: The path of pretrained checkpoints.\n",
        "  *   `num_classes`: The number of classes in the training/validation data.\n",
        "  *   `max_steps`: The number of steps that the training job will run.\n",
        "  *   `train_batch_size`: The number of images used in one training step.\n",
        "  *   `num_eval_images`:  The number of total images used for evaluation. Its value needs to be equal or less than the total images in the validation_data_path.\n",
        "  *   `learning_rate_decay_type`: The type that learning rate decays during training. Needs to be one of `{cosine, stepwise}`.\n",
        "  *   `warmup_learning_rate`: The initial learning rate during warm-up phase.\n",
        "  *   `warmup_steps`:  The number of steps to warm-up: the step from warmup_learning_rate to reach Initial Learning Rate.\n",
        "  *    `initial_learning_rate`:  The initial learning rate after warmup period.\n",
        "  *    `stepwise_learning_rate_steps`:  The steps to decay/change learning rates for stepwise learning rate decay type. For example, 100,200 means the learning rate will change (with respect to  stepwise_learning_rate_levels) at step 100 and step 200. Note that it will be respected only when learning_rate_decay_type is set to stepwise.\n",
        "  *    `stepwise_learning_rate_levels`:  The learning rate value of each step  for stepwise learning rate decay type. Note that it will be respected only when learning_rate_decay_type is set to stepwise.\n",
        "  *    `optimizer_type`:  The optimizer used for training. It should be  one of `{momentum, adam, adadelta, adagrad, rmsprop}`.\n",
        "  *    `image_size`:  The image size (height and width) used for training, e.g., \"640,640\".\n",
        "  *    `resnet_depth`: The depth of ResNet backbone. Need to be one of `{18,34,50,101,152,200}`.\n",
        "  *    `anchor_size`: The  scale of the base anchor size in Feature Pyramid Network (FPN).\n",
        "  *    `fpn_type`:  The multi-level Feature Pyramid Network (FPN) type. Need to be one of `{fpn, nasfpn}`.\n",
        "  *    `bbox_aspect_ratios`: The scale of size of the base anchors representing the aspect raito anchors added on each level. The number indicates the ratio of width to height. For instances, `“1.0,2.0,0.5”` adds three anchors on each scale level.\n",
        "  *    `max_num_bboxes_in_training`: The maximum number of proposed bboxes proposed for training.\n",
        "  *    `max_num_bboxes_in_prediction`: The maximum number of proposed bboxes in prediction outputs.\n",
        "  *    `nms_iou_threshold`: The threshold to decide whether bboxes overlap with respect to 'IOU for non-maximum suppression.\n",
        "  *    `nms_score_threshold`: The threshold for deciding when to remove boxes based on score.\n",
        "  *    `focal_loss_alpha`: Focal loss alpha (balancing param) value.\n",
        "  *    `focal_loss_gamma`: Focal loss gamma (focusing param) value.\n",
        "  *    `aug_scale_min`: The minimum scale applied during image augmentation. Its value is between `[0, 1.0]`.\n",
        "  *    `aug_scale_max`: The maximum scale applied during image augmentation. Its value is between `[1.0, inf]`.\n",
        "  *    `aug_rand_hflip`: If true, augment training with random\n",
        "        horizontal flip."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7IlL0ReyUpT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from time import gmtime, strftime\n",
        "import json\n",
        "\n",
        "DATASET_NAME = 'coco'\n",
        "ALGORITHM = 'object_detection'\n",
        "MODEL_TYPE = 'retinanet'\n",
        "MODEL_NAME =  '{}_{}_{}'.format(DATASET_NAME, ALGORITHM, MODEL_TYPE)\n",
        "\n",
        "# Give a unique name to your Codeless Cloud ML Engine training job.\n",
        "timestamp = strftime(\"%Y%m%d%H%M%S\", gmtime())\n",
        "JOB_ID='{}_{}'.format(MODEL_NAME, timestamp)\n",
        "\n",
        "# This is where all your model related files will be saved. Make sure you have access to this GCS bucket.\n",
        "JOB_DIR='{}/{}'.format(JOB_OUTPUT_BUCKET, JOB_ID)\n",
        "\n",
        "# Sets the machine configuration of training jobs.\n",
        "TRAINING_INPUT = \"\"\"trainingInput:\n",
        "  scaleTier: CUSTOM\n",
        "  masterType: n1-highmem-16\n",
        "  masterConfig:\n",
        "    imageUri: gcr.io/cloud-ml-algos/image_object_detection:latest\n",
        "    acceleratorConfig:\n",
        "      type: NVIDIA_TESLA_P100\n",
        "      count: 1\n",
        "  workerType:  cloud_tpu\n",
        "  workerConfig:\n",
        "   imageUri: gcr.io/cloud-ml-algos/image_object_detection:latest\n",
        "   acceleratorConfig:\n",
        "     type: TPU_V2\n",
        "     count: 8\n",
        "  workerCount: 1\"\"\"\n",
        "with open('config.yaml', 'w') as f:\n",
        "  f.write(TRAINING_INPUT)\n",
        "\n",
        "# Launch AI platform training job.\n",
        "! gcloud ai-platform jobs submit training $JOB_ID \\\n",
        "  --region=us-central1 \\\n",
        "  --config=config.yaml \\\n",
        "  --job-dir=$JOB_DIR \\\n",
        "  -- \\\n",
        "  --training_data_path=gs://builtin-algorithm-data-public/coco/train* \\\n",
        "  --validation_data_path=gs://builtin-algorithm-data-public/coco/val* \\\n",
        "  --max_steps=90000 \\\n",
        "  --train_batch_size=64 \\\n",
        "  --num_eval_images=5000 \\\n",
        "  --num_classes=91 \\\n",
        "  --initial_learning_rate=0.08 \\\n",
        "  --learning_rate_decay_type=stepwise \\\n",
        "  --stepwise_learning_rate_levels=\"0.008,0.0008\" \\\n",
        "  --stepwise_learning_rate_steps=\"60000,80000\" \\\n",
        "  --warmup_steps=1733 \\\n",
        "  --aug_scale_min=0.8 \\\n",
        "  --aug_scale_max=1.2 \\\n",
        "  --fpn_type=fpn \\\n",
        "  --pretrained_checkpoint_path=\"gs://builtin-algorithm-data-public/pretrained_checkpoints/detection/resnet50/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aYXTQuhUswg",
        "colab_type": "text"
      },
      "source": [
        "## Submitting a training Job with Hyperparameter Tuning \n",
        "\n",
        "\n",
        "###  **Note that to support parallel jobs during hyperparameter tuning, you may need to [Requesting a quota increase](https://cloud.google.com/ml-engine/docs/quotas) to get more TPU/GPU resources.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SW7Nor-oU0kz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from time import gmtime, strftime\n",
        "import json\n",
        "\n",
        "DATASET_NAME = 'coco_hypertune'\n",
        "ALGORITHM = 'detection'\n",
        "MODEL_TYPE = 'retinanet'\n",
        "MODEL_NAME =  '{}_{}_{}'.format(DATASET_NAME, ALGORITHM, MODEL_TYPE)\n",
        "\n",
        "# Give a unique name to your Codeless Cloud ML Engine training job.\n",
        "timestamp = strftime(\"%Y%m%d%H%M%S\", gmtime())\n",
        "JOB_ID='{}_{}'.format(MODEL_NAME, timestamp)\n",
        "\n",
        "# This is where all your model related files will be saved. Make sure you have access to this GCS bucket.\n",
        "JOB_DIR='{}/{}'.format(JOB_OUTPUT_BUCKET, JOB_ID)\n",
        "\n",
        "# Sets the machine configuration of training jobs.\n",
        "TRAINING_INPUT = \"\"\"trainingInput:\n",
        "  scaleTier: CUSTOM\n",
        "  masterType: n1-highmem-16\n",
        "  masterConfig:\n",
        "    imageUri: gcr.io/cloud-ml-algos/image_object_detection:latest\n",
        "    acceleratorConfig:\n",
        "      type: NVIDIA_TESLA_P100\n",
        "      count: 1\n",
        "  workerType:  cloud_tpu\n",
        "  workerConfig:\n",
        "   imageUri: gcr.io/cloud-ml-algos/image_object_detection:latest\n",
        "   acceleratorConfig:\n",
        "     type: TPU_V2\n",
        "     count: 8\n",
        "  workerCount: 1\n",
        "  # The following are hyper-parameter configs.\n",
        "  hyperparameters:\n",
        "   goal: MAXIMIZE\n",
        "   hyperparameterMetricTag: \"AP\"\n",
        "   maxTrials: 2\n",
        "   maxParallelTrials: 2\n",
        "   params:\n",
        "    - parameterName: fpn_type\n",
        "      type: CATEGORICAL\n",
        "      categoricalValues:\n",
        "      - fpn\n",
        "      - nasfpn\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "with open('config.yaml', 'w') as f:\n",
        "  f.write(TRAINING_INPUT)\n",
        "\n",
        "# Launch AI platform training job.\n",
        "! gcloud ai-platform jobs submit training $JOB_ID \\\n",
        "  --region=us-central1 \\\n",
        "  --config=config.yaml \\\n",
        "  --job-dir=$JOB_DIR \\\n",
        "  -- \\\n",
        "  --training_data_path=gs://builtin-algorithm-data-public/coco/train* \\\n",
        "  --validation_data_path=gs://builtin-algorithm-data-public/coco/val* \\\n",
        "  --max_steps=90000 \\\n",
        "  --train_batch_size=64 \\\n",
        "  --num_eval_images=5000 \\\n",
        "  --num_classes=91 \\\n",
        "  --initial_learning_rate=0.08 \\\n",
        "  --learning_rate_decay_type=stepwise \\\n",
        "  --stepwise_learning_rate_levels=\"0.008,0.0008\" \\\n",
        "  --stepwise_learning_rate_steps=\"60000,80000\" \\\n",
        "  --warmup_steps=1733 \\\n",
        "  --aug_scale_min=0.8 \\\n",
        "  --aug_scale_max=1.2 \\\n",
        "  --fpn_type=fpn \\\n",
        "  --pretrained_checkpoint_path=\"gs://builtin-algorithm-data-public/pretrained_checkpoints/detection/resnet50/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTaYmcZfBoQZ",
        "colab_type": "text"
      },
      "source": [
        "## Monitor submitted training job"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mje36Q238T-e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gcloud ai-platform jobs describe {JOB_ID}\n",
        "!gcloud ai-platform jobs stream-logs {JOB_ID}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyfU8q5ejTl5",
        "colab_type": "text"
      },
      "source": [
        "## Track training progress with TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcWXr5FuBZeB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use tensorboard to monitor the progress. \n",
        "# May need to wait for a few minutes until tensorflow metrics are available.\n",
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir $JOB_DIR"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdCR0VRudrZo",
        "colab_type": "text"
      },
      "source": [
        "## Copy `Best` SavedModel to local\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08K1oo89CtCC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copy SavedModel to local.\n",
        "\n",
        "!gsutil cp -r $JOB_DIR/model .\n",
        "\n",
        "# Use the following command if it is a hyperparameter tuning job.\n",
        "# TRIAL_ID=1\n",
        "# !gsutil cp -r $JOB_DIR/{TRIAL_ID}/model .\n",
        "\n",
        "\n",
        "print('\\nThe generated SavedModel has the following signature:')\n",
        "!saved_model_cli show --dir model --tag_set serve --signature_def serving_default"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOT8EyAlmkgm",
        "colab_type": "text"
      },
      "source": [
        "## Run prediction locally"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpFlkFp7iOxr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "# For downloading the image.\n",
        "import matplotlib.pyplot as plt\n",
        "import tempfile\n",
        "from six.moves.urllib.request import urlopen\n",
        "from six import BytesIO\n",
        "\n",
        "# For drawing onto the image.\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from PIL import ImageColor\n",
        "from PIL import ImageDraw\n",
        "from PIL import ImageFont\n",
        "from PIL import ImageOps\n",
        "\n",
        "# For measuring the inference time.\n",
        "import time\n",
        "\n",
        "# Use coco sample image for prediction.\n",
        "IMAGE_URI='gs://builtin-algorithm-data-public/testing_images/detection/coco_sample.jpeg'\n",
        "\n",
        "\n",
        "# Check available GPU devices.\n",
        "print(\"The following GPU devices are available: %s\" % tf.test.gpu_device_name())\n",
        "def display_image(image):\n",
        " fig = plt.figure(figsize=(20, 15))\n",
        " plt.grid(False)\n",
        " plt.imshow(image)\n",
        "\n",
        "\n",
        "def draw_bounding_box_on_image(image,\n",
        "                              ymin,\n",
        "                              xmin,\n",
        "                              ymax,\n",
        "                              xmax,\n",
        "                              color,\n",
        "                              font,\n",
        "                              thickness=4,\n",
        "                              display_str_list=()):\n",
        " \"\"\"Adds a bounding box to an image.\"\"\"\n",
        " draw = ImageDraw.Draw(image)\n",
        " im_width, im_height = image.size\n",
        " (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n",
        "                               ymin * im_height, ymax * im_height)\n",
        " draw.line([(left, top), (left, bottom), (right, bottom), (right, top),\n",
        "            (left, top)],\n",
        "           width=thickness,\n",
        "           fill=color)\n",
        "\n",
        " # If the total height of the display strings added to the top of the bounding\n",
        " # box exceeds the top of the image, stack the strings below the bounding box\n",
        " # instead of above.\n",
        " display_str_heights = [font.getsize(ds)[1] for ds in display_str_list]\n",
        " # Each display_str has a top and bottom margin of 0.05x.\n",
        " total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights)\n",
        "\n",
        " if top > total_display_str_height:\n",
        "   text_bottom = top\n",
        " else:\n",
        "   text_bottom = bottom + total_display_str_height\n",
        " # Reverse list and print from bottom to top.\n",
        " for display_str in display_str_list[::-1]:\n",
        "   text_width, text_height = font.getsize(display_str)\n",
        "   margin = np.ceil(0.05 * text_height)\n",
        "   draw.rectangle([(left, text_bottom - text_height - 2 * margin),\n",
        "                   (left + text_width, text_bottom)],\n",
        "                  fill=color)\n",
        "   draw.text((left + margin, text_bottom - text_height - margin),\n",
        "             display_str,\n",
        "             fill=\"black\",\n",
        "             font=font)\n",
        "   text_bottom -= text_height - 2 * margin\n",
        "\n",
        "img = tf.io.read_file(IMAGE_URI)\n",
        "img = tf.image.decode_jpeg(img, channels=3)\n",
        "\n",
        "def draw_boxes(image, boxes, class_names, scores, max_boxes=10, min_score=0.1):\n",
        "  \"\"\"Overlay labeled boxes on an image with formatted scores and label names.\"\"\"\n",
        "  colors = list(ImageColor.colormap.values())\n",
        "\n",
        "  try:\n",
        "    font = ImageFont.truetype(\"/usr/share/fonts/truetype/liberation/LiberationSansNarrow-Regular.ttf\",\n",
        "                              25)\n",
        "  except IOError:\n",
        "    print(\"Font not found, using default font.\")\n",
        "    font = ImageFont.load_default()\n",
        "\n",
        "  for i in range(min(boxes.shape[0], max_boxes)):\n",
        "    if scores[i] >= min_score:\n",
        "      ymin, xmin, ymax, xmax = tuple(boxes[i])\n",
        "      display_str = \"{}: {}%\".format(class_names[i],\n",
        "                                     int(100 * scores[i]))\n",
        "      color = colors[hash(class_names[i]) % len(colors)]\n",
        "      image_pil = Image.fromarray(np.uint8(image)).convert(\"RGB\")\n",
        "      draw_bounding_box_on_image(\n",
        "          image_pil,\n",
        "          ymin,\n",
        "          xmin,\n",
        "          ymax,\n",
        "          xmax,\n",
        "          color,\n",
        "          font,\n",
        "          display_str_list=[display_str])\n",
        "      np.copyto(image, np.array(image_pil))\n",
        "  return image\n",
        "\n",
        "\n",
        "predict_fn = tf.contrib.predictor.from_saved_model(\n",
        "    export_dir='model',\n",
        "    signature_def_key='serving_default')\n",
        "\n",
        "\n",
        "with tf.gfile.FastGFile(IMAGE_URI) as img_file:\n",
        "  img_data = img_file.read()\n",
        "  image = [img_data]\n",
        "  predictions = predict_fn({\n",
        "      'encoded_image': image,\n",
        "      'key': ['key']\n",
        "  })\n",
        "\n",
        "# print predictions\n",
        "\n",
        "sess=tf.Session()\n",
        "with sess.as_default():\n",
        "#  display_image(img.eval())\n",
        " image_with_boxes = draw_boxes(\n",
        "   img.eval(), predictions[\"detection_boxes\"][0],\n",
        "   predictions[\"detection_classes\"][0], predictions[\"detection_scores\"][0])\n",
        "\n",
        " display_image(image_with_boxes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcXmIX68O0bd",
        "colab_type": "text"
      },
      "source": [
        "## Deploying trained model in Cloud AI platform for online prediction in production\n",
        "\n",
        "After training is done, you should expect the following directory structure under your `JOB_DIR`.\n",
        "\n",
        "*   model/\n",
        "  * saved_model.pb\n",
        "  * variables\n",
        "  * deployment_config.yaml\n",
        "\n",
        "The deployment_config.yaml file should contain something like :\n",
        "```\n",
        "deploymentUri: gs://JOB_DIR/model\n",
        "framework: TENSORFLOW\n",
        "labels:\n",
        "  job_id: {JOB_NAME}\n",
        "  gloabal_step: '1000'\n",
        "runtimeVersion: '1.14'\n",
        "```\n",
        "\n",
        "Let's try to use this file to deploy our model in prediction and make predictions from it.\n",
        "\n",
        "For more details on how to make deployments on AI platform, take a look at [how to deploy a TensorFlow model on CMLE](https://cloud.google.com/ml-engine/docs/tensorflow/deploying-models)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e71sLHw8wg3B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's copy the file to our local directory and take a look at the file.\n",
        "!gsutil cp {JOB_DIR}/model/deployment_config.yaml .\n",
        "\n",
        "\n",
        "# Use the following command if it is a hyperparameter tuning job.\n",
        "# TRIAL_ID=1\n",
        "# !gsutil cp {JOB_DIR}/{TRIAL_ID}/model/deployment_config.yaml .\n",
        "\n",
        "print('\\nThe job deployment_config.yaml is:')\n",
        "!cat deployment_config.yaml"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffMut-a_wpai",
        "colab_type": "text"
      },
      "source": [
        "Let's create the model and version in AI Platform:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D531YAAHQfJB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gcloud ai-platform models create {MODEL_NAME} --regions {REGION}\n",
        "\n",
        "# Create a model and a version using the file above.\n",
        "VERSION_NAME=JOB_ID\n",
        "\n",
        "!echo \"Deployment takes a couple of minutes. You can watch your deployment here: https://console.cloud.google.com/mlengine/models/{MODEL_NAME}\"\n",
        "\n",
        "# If {MODEL_NAME} and {VERSION_NAME} already exists, you can delete the version first:\n",
        "# !gcloud ai-platform versions delete {VERSION_NAME} --model={MODEL_NAME}\n",
        "\n",
        "!gcloud ai-platform versions create {VERSION_NAME} \\\n",
        "  --model {MODEL_NAME} \\\n",
        "  --config deployment_config.yaml\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6T7mOcVGQ6m2",
        "colab_type": "text"
      },
      "source": [
        "Now we can make prediction using the deployed model and display image with detected bounding boxes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCiQVww6Ozje",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import base64\n",
        "import json \n",
        "\n",
        "with tf.gfile.Open(IMAGE_URI, 'rb') as image_file:\n",
        "  encoded_string = base64.b64encode(image_file.read()).decode('utf-8')\n",
        "\n",
        "image_bytes = {'b64': str(encoded_string)}\n",
        "instances = {'encoded_image': image_bytes, 'key': '1'}\n",
        "with open(\"prediction_instances.json\",\"w\") as f:\n",
        "  f.write(json.dumps(instances)) \n",
        "  \n",
        "!gcloud ai-platform predict --model $MODEL_NAME \\\n",
        " --version $VERSION_NAME \\\n",
        " --json-instances prediction_instances.json > ./output.txt\n",
        " \n",
        "box_str=!tail -1 output.txt | sed 's/\\]\\]/\\]\\];/g' | cut -d ';' -f 1\n",
        "class_str=!tail -1 output.txt | sed 's/\\]\\]/\\]\\];/g' | cut -d ';' -f 2- | cut -d ']' -f 1 | cut -d '[' -f 2-\n",
        "score_str=!tail -1 output.txt | sed 's/\\]\\]/\\]\\];/g' | cut -d ';' -f 2- | cut -d ']' -f 2 | cut -d '[' -f 2-\n",
        "cnt_str=!tail -1 output.txt | sed 's/\\]\\]/\\]\\];/g' | cut -d ';' -f 2- | cut -d ']' -f 3 |cut -d ' ' -f 5-\n",
        "boxes=np.array(json.loads(box_str[0]))\n",
        "classes=np.fromstring(class_str[0], dtype=np.float, sep=', ')\n",
        "scores=np.fromstring(score_str[0], dtype=np.float, sep=', ')\n",
        "cnt=np.fromstring(cnt_str[0], dtype=np.float, sep =' ')\n",
        "sess=tf.Session()\n",
        "with sess.as_default():\n",
        "image_with_boxes_clme = draw_boxes(img.eval(), boxes, classes, scores)\n",
        "display_image(image_with_boxes_clme)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}