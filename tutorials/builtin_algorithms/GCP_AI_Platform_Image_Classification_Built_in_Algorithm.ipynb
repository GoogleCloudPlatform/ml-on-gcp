{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GCP AI Platform Image Classification Built-in Algorithm.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "_aYXTQuhUswg"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jys-gg/ml-on-gcp/blob/master/GCP_AI_Platform_Image_Classification_Built_in_Algorithm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "deletable": true,
        "editable": true,
        "id": "qnMpW5Y9nv2l",
        "colab": {}
      },
      "source": [
        "# Copyright 2019 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ro0sBUyegE-U",
        "colab_type": "text"
      },
      "source": [
        "# GCP AI Platform Built-in Algorithm: Image Classification\n",
        "\n",
        "In this tutorial we will train an image classification model (with TPU) and then deploy it to AI platform for prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPWmrseGcPUm",
        "colab_type": "text"
      },
      "source": [
        "## Setting up Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOK96Jedv566",
        "colab_type": "text"
      },
      "source": [
        "### Set up your GCP project following the [instructions](https://cloud.google.com/ml-engine/docs/tensorflow/getting-started-training-prediction#setup):\n",
        "\n",
        "\n",
        "\n",
        "*   Select or create a GCP project.\n",
        "*   Make sure that billing is enabled for your Google Cloud Platform project.\n",
        "*   Enable the AI Platform (\"Cloud Machine Learning Engine\") and Compute Engine APIs. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndb_6SugtlzH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install google-cloud\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "humJz-nxwhJG",
        "colab": {}
      },
      "source": [
        "# Set the GCP project-id and region, and bucket.\n",
        "\n",
        "# Please use your own project_id.\n",
        "PROJECT_ID=''\n",
        "REGION='us-central1'\n",
        "\n",
        "!gcloud config set project {PROJECT_ID}\n",
        "!gcloud config set compute/region {REGION}\n",
        "\n",
        "# Create bucket (it is ok if the bucket has already been created)\n",
        "JOB_OUTPUT_BUCKET=\"gs://{}_image_classification\".format(PROJECT_ID)\n",
        "! echo $JOB_OUTPUT_BUCKET\n",
        "!gsutil mkdir -p $PROJECT_ID $JOB_OUTPUT_BUCKET"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoFaJ1-BNcZf",
        "colab_type": "text"
      },
      "source": [
        "### Setup TPU for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5lrtt3Axdzh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "\n",
        "!curl -H \"Authorization: Bearer $(gcloud auth print-access-token)\"  \\\n",
        "    https://ml.googleapis.com/v1/projects/$PROJECT_ID:getConfig | cat > ./access_token.json\n",
        "    \n",
        "with open('access_token.json', 'r') as f:\n",
        "  TPU_SERVICE_ACCOUNT=json.load(f)['config']['tpuServiceAccount']    \n",
        "\n",
        "!echo \"Adding TPU service account for $TPU_SERVICE_ACCOUNT\"\n",
        "\n",
        "!gcloud projects add-iam-policy-binding $PROJECT_ID \\\n",
        "    --member serviceAccount:$TPU_SERVICE_ACCOUNT --role roles/ml.serviceAgent"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ksBs1CD3_cD",
        "colab_type": "text"
      },
      "source": [
        "## Submitting a training Job\n",
        "\n",
        "To submit a job we need to specify some basic training arguments and some basic arguments related to our algorithm.\n",
        "\n",
        "Let's start with setting up arguments and using gcloud to submit the Job.\n",
        "* Training Job arguments: `job_id, scale-tier, master-image-uri, region`.\n",
        "* Algorithm Arguments: \n",
        "  *   `training_data_path`: Path to a TFRecord path pattern used for training.\n",
        "  *   `validation_data_path`: Path to a TFRecord path pattern used for validation.\n",
        "  *   `job-dir`: Path where model, checkpoints and other training artifacts will reside.\n",
        "  *   `num_classes`: The number of classes in the training/validation data.\n",
        "  *   `max_steps`: The number of steps that the training job will run.\n",
        "  *   `train_batch_size`: The number of images used in one training step.\n",
        "  *   `num_eval_images`:  The number of total images used for evaluation. Its value needs to be equal or less than the total images in the `validation_data_path`.\n",
        "  *   `learning_rate_decay_type`: The type that learning rate decays during training.\n",
        "  *   `warmup_learning_rate`: The initial learning rate during warm-up phase.\n",
        "  *   `warmup_steps`:  The number of steps to warm-up: the step from warmup_learning_rate to reach Initial Learning Rate.\n",
        "  *    `initial_learning_rate`:  The initial learning rate after warmup period.\n",
        "  *    `stepwise_learning_rate_steps`:  The steps to decay/change learning rates for stepwise learning rate decay type. For example, 100,200 means the learning rate will change (with respect to  stepwise_learning_rate_levels) at step 100 and step 200. Note that it will be respected only when learning_rate_decay_type is set to stepwise.\n",
        "  *    `stepwise_learning_rate_levels`:  The learning rate value of each step  for stepwise learning rate decay type. Note that it will be respected only when learning_rate_decay_type is set to stepwise.\n",
        "  *    `optimizer_type`:  The optimizer used for training. It should be one of {momentum, adam, rmsprop}.\n",
        "  *    `optimizer_arguments`:  The arguments for optimizer. It is a comma separated list of \"name=value\" pairs. It needs to be compatible with optimizer_type. For example, for Momentum optimizer, it accepts \"momentum=0.9\". See tf.train.MomentumOptimizer for more details. For Adam optimizer, it can be \"beta1=0.9,beta2=0.999\". See tf.train.AdamOptimizer for more details. For RMSProp optimizer, it can be \"decay=0.9,momentum=0.1,epsilon=1e-10\". See RMSPropOptimizer for more details.\n",
        "  *    `image_size`:  The image size (width and height) used for training.\n",
        "  *    `model_type`:  That model architecture type used to train models. It can be one of `{resnet-(18|34|50|101|152|200), efficientnet-(b0|b1|b2|b3|b4|b5|b6|b7)}`.\n",
        "  *    `label_smoothing`:  Label smoothing parameter used in the softmax_cross_entropy.\n",
        "  *    `weight_decay`:  Weight decay co-efficiant for l2 regularization, e.g.,  `loss = cross_entropy + params['weight_decay']*l2_loss`.\n",
        "  *    `pretrained_checkpoint_path`: The path of pretrained checkpoints.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7IlL0ReyUpT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from time import gmtime, strftime\n",
        "import json\n",
        "\n",
        "DATASET_NAME = 'flower'\n",
        "ALGORITHM = 'classification'\n",
        "MODEL_TYPE = 'efficientetb4'\n",
        "MODEL_NAME =  '{}_{}_{}'.format(DATASET_NAME, ALGORITHM, MODEL_TYPE)\n",
        "print(MODEL_NAME)\n",
        "\n",
        "# Give a unique name to your Codeless Cloud ML Engine training job.\n",
        "timestamp = strftime(\"%Y%m%d%H%M%S\", gmtime())\n",
        "JOB_ID='{}_{}'.format(MODEL_NAME, timestamp)\n",
        "\n",
        "# This is where all your model related files will be saved.\n",
        "JOB_DIR='{}/{}'.format(JOB_OUTPUT_BUCKET, JOB_ID)\n",
        "\n",
        "# Sets the machine configuration of training jobs.\n",
        "TRAINING_INPUT = \"\"\"trainingInput:\n",
        "  scaleTier: CUSTOM\n",
        "  masterType: n1-highmem-16\n",
        "  masterConfig:\n",
        "    imageUri: gcr.io/cloud-ml-algos/image_classification:latest\n",
        "  workerType:  cloud_tpu\n",
        "  workerConfig:\n",
        "   imageUri: gcr.io/cloud-ml-algos/image_classification:latest\n",
        "   acceleratorConfig:\n",
        "     type: TPU_V2\n",
        "     count: 8\n",
        "  workerCount: 1\"\"\"\n",
        "with open('config.yaml', 'w') as f:\n",
        "  f.write(TRAINING_INPUT)\n",
        "\n",
        "# Launch AI platform training job.\n",
        "! gcloud ai-platform jobs submit training $JOB_ID \\\n",
        "  --region=us-central1 \\\n",
        "  --config=config.yaml \\\n",
        "  --master-image-uri=gcr.io/cloud-ml-algos/image_classification:latest \\\n",
        "  -- \\\n",
        "  --training_data_path=gs://builtin-algorithm-data-public/flowers/flowers_train* \\\n",
        "  --validation_data_path=gs://builtin-algorithm-data-public/flowers/flowers_validation* \\\n",
        "  --job-dir=$JOB_DIR \\\n",
        "  --max_steps=50000 \\\n",
        "  --train_batch_size=128 \\\n",
        "  --num_eval_images=10 \\\n",
        "  --num_classes=5 \\\n",
        "  --initial_learning_rate=0.128 \\\n",
        "  --optimizer_type='momentum' \\\n",
        "  --optimizer_arguments='momentum=0.9,use_nesterov=False' \\\n",
        "  --learning_rate_decay_type=cosine \\\n",
        "  --warmup_steps=500 \\\n",
        "  --model_type='efficientnet-b4'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aYXTQuhUswg",
        "colab_type": "text"
      },
      "source": [
        "## Submitting a training Job with Hyperparameter Tuning\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SW7Nor-oU0kz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from time import gmtime, strftime\n",
        "import json\n",
        "\n",
        "DATASET_NAME = 'flower'\n",
        "ALGORITHM = 'classification'\n",
        "MODEL_TYPE = 'efficientetb4'\n",
        "MODEL_NAME =  '{}_{}_{}'.format(DATASET_NAME, ALGORITHM, MODEL_TYPE)\n",
        "\n",
        "# Give a unique name to your Codeless Cloud ML Engine training job.\n",
        "timestamp = strftime(\"%Y%m%d%H%M%S\", gmtime())\n",
        "JOB_ID='{}_{}'.format(MODEL_NAME, timestamp)\n",
        "\n",
        "# This is where all your model related files will be saved.\n",
        "JOB_OUTPUT_BUCKET=\"gs://test_oob_classification\"\n",
        "!gsutil mkdir $JOB_OUTPUT_BUCKET\n",
        "\n",
        "JOB_DIR='{}/{}'.format(JOB_OUTPUT_BUCKET, JOB_ID)\n",
        "\n",
        "# Sets the machine configuration of training jobs.\n",
        "TRAINING_INPUT = \"\"\"trainingInput:\n",
        "  scaleTier: CUSTOM\n",
        "  masterType: n1-highmem-16\n",
        "  masterConfig:\n",
        "    imageUri: gcr.io/cloud-ml-algos/image_classification:latest\n",
        "  workerType:  cloud_tpu\n",
        "  workerConfig:\n",
        "   imageUri: gcr.io/cloud-ml-algos/image_classification:latest\n",
        "   acceleratorConfig:\n",
        "     type: TPU_V2\n",
        "     count: 8\n",
        "  workerCount: 1\n",
        "  # The following are hyper-parameter configs.\n",
        "  hyperparameters:\n",
        "   goal: MAXIMIZE\n",
        "   hyperparameterMetricTag: \"top_1_accuracy\"\n",
        "   maxTrials: 6\n",
        "   maxParallelTrials: 3\n",
        "   enableTrialEarlyStopping: True\n",
        "   params:\n",
        "   - parameterName: initial_learning_rate\n",
        "     type: DOUBLE\n",
        "     minValue: 0.001\n",
        "     maxValue: 0.1\n",
        "     scaleType: UNIT_LOG_SCALE\n",
        "  \"\"\"\n",
        "with open('config.yaml', 'w') as f:\n",
        "  f.write(TRAINING_INPUT)\n",
        "\n",
        "# Launch AI platform training job.\n",
        "! gcloud ai-platform jobs submit training $JOB_ID \\\n",
        "  --region=us-central1 \\\n",
        "  --config=config.yaml \\\n",
        "  --master-image-uri=gcr.io/cloud-ml-algos/image_classification:latest \\\n",
        "  -- \\\n",
        "  --training_data_path=gs://builtin-algorithm-data-public/flowers/flowers_train* \\\n",
        "  --validation_data_path=gs://builtin-algorithm-data-public/flowers/flowers_validation* \\\n",
        "  --job-dir=$JOB_DIR \\\n",
        "  --max_steps=300000 \\\n",
        "  --train_batch_size=128 \\\n",
        "  --eval_batch_size=100 \\\n",
        "  --num_eval_images=0 \\\n",
        "  --num_classes=5 \\\n",
        "  --initial_learning_rate=0.128 \\\n",
        "  --decay_steps=300000 \\\n",
        "  --optimizer_type='momentum' \\\n",
        "  --optimizer_arguments='momentum=0.9,use_nesterov=False' \\\n",
        "  --learning_rate_decay_type=cosine \\\n",
        "  --warmup_steps=2000 \\\n",
        "  --model_type='efficientnet-b4'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTaYmcZfBoQZ",
        "colab_type": "text"
      },
      "source": [
        "## `Monitor submitted training job`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mje36Q238T-e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gcloud ai-platform jobs describe {JOB_ID}\n",
        "!gcloud ai-platform jobs stream-logs {JOB_ID}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyfU8q5ejTl5",
        "colab_type": "text"
      },
      "source": [
        "## Track training progress with TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcWXr5FuBZeB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use tensorboard to monitor the progress.\n",
        "# May need to wait for a few minutes until tensorflow metrics are available.\n",
        "# Need to stop the process on `Monitor submitted training job` to start tensorboard.\n",
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir $JOB_DIR"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdCR0VRudrZo",
        "colab_type": "text"
      },
      "source": [
        "## Run prediction locally\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08K1oo89CtCC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copy SavedModel to local. Need to wait until there is SavedModel available.\n",
        "\n",
        "JOB_DIR=''\n",
        "!gsutil cp -r $JOB_DIR/model .\n",
        "\n",
        "# Use the following command if it is a hyperparameter tuning job.\n",
        "# TRIAL_ID=1\n",
        "# !gsutil cp -r $JOB_DIR/{TRIAL_ID}/model .\n",
        "\n",
        "\n",
        "print('\\nThe generated SavedModel has the following signature:')\n",
        "!saved_model_cli show --dir model --tag_set serve --signature_def classify"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRJhKaAPMBlR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run prediction locally:\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "predict_fn = tf.contrib.predictor.from_saved_model(\n",
        "    export_dir='model',\n",
        "    signature_def_key='classify')\n",
        "\n",
        "IMAGE_URI='gs://download.tensorflow.org/example_images/grace_hopper.jpg'\n",
        "\n",
        "with tf.gfile.FastGFile(IMAGE_URI, 'rb') as img_file:\n",
        "  img_data = img_file.read()\n",
        "  image = [img_data]\n",
        "  predictions = predict_fn({\n",
        "      'image_bytes': image,\n",
        "      'key': ['test_key']\n",
        "  })\n",
        "  print('The predicted class is {}'.format(predictions['classes']))\n",
        "  print('probabilities is {}'.format(predictions['probabilities']))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcXmIX68O0bd",
        "colab_type": "text"
      },
      "source": [
        "## Deploying trained model in Cloud AI platform for online prediction in production\n",
        "\n",
        "After training is done, you should expect the following directory structure under your `JOB_DIR`.\n",
        "\n",
        "*   model/\n",
        "  * saved_model.pb\n",
        "  * variables\n",
        "  * deployment_config.yaml\n",
        "\n",
        "The deployment_config.yaml file should contain something like :\n",
        "```\n",
        "deploymentUri: gs://JOB_DIR/model\n",
        "framework: TENSORFLOW\n",
        "labels:\n",
        "  job_id: {JOB_NAME}\n",
        "  gloabal_step: '1000'\n",
        "runtimeVersion: '1.13'\n",
        "```\n",
        "\n",
        "Let's try to use this file to deploy our model in prediction and make predictions from it.\n",
        "\n",
        "For more details on how to make deployments on AI platform, take a look at [how to deploy a TensorFlow model on CMLE](https://cloud.google.com/ml-engine/docs/tensorflow/deploying-models)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e71sLHw8wg3B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's copy the file to our local directory and take a look at the file.\n",
        "!gsutil cp {JOB_DIR}/model/deployment_config.yaml .\n",
        "\n",
        "# Use the following command if it is a hyperparameter tuning job.\n",
        "# TRIAL_ID=1\n",
        "# !gsutil cp {JOB_DIR}/{TRIAL_ID}/model/deployment_config.yaml .\n",
        "\n",
        "print('\\nThe job deployment_config.yaml is:')\n",
        "!cat deployment_config.yaml"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffMut-a_wpai",
        "colab_type": "text"
      },
      "source": [
        "Let's create the model and version in AI Platform:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D531YAAHQfJB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gcloud ai-platform models create {MODEL_NAME} --regions {REGION}\n",
        "\n",
        "# Create a model and a version using the file above.\n",
        "VERSION_NAME=JOB_ID\n",
        "\n",
        "!echo \"Deployment takes a couple of minutes. You can watch your deployment here: https://console.cloud.google.com/mlengine/models/{MODEL_NAME}\"\n",
        "\n",
        "!gcloud ai-platform versions create {VERSION_NAME} \\\n",
        "  --model {MODEL_NAME} \\\n",
        "  --config deployment_config.yaml"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6T7mOcVGQ6m2",
        "colab_type": "text"
      },
      "source": [
        "Now we can make prediction using the deployed model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCiQVww6Ozje",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json \n",
        "import base64\n",
        "\n",
        "with tf.gfile.Open(IMAGE_URI, 'rb') as image_file:\n",
        "  encoded_string = base64.b64encode(image_file.read()).decode('utf-8')\n",
        "\n",
        "image_bytes = {'b64': str(encoded_string)}\n",
        "instances = {'image_bytes': image_bytes, 'key': '1'}\n",
        "with open(\"prediction_instances.json\",\"w\") as f:\n",
        "  f.write(json.dumps(instances)) \n",
        "  \n",
        "!gcloud ml-engine predict --model $MODEL_NAME \\\n",
        "  --version $VERSION_NAME \\\n",
        "  --json-instances prediction_instances.json\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
