name: mlflow_gcp
docker_env:
  image: mlflow-gcp-example
entry_points:
  main:
    parameters:
      job_dir:
        type: string
        default: '/tmp/'
      num_epochs:
        type: int
        default: 10
      train_steps:
        type: int
        default: 1000
      eval_steps:
        type: int
        default: 1
      batch_size:
        type: int
        default: 128
      train_files:
        type: string
        default: 'gs://cloud-samples-data/ml-engine/census/data/adult.data.csv'
      eval_files:
        type: string
        default: 'gs://cloud-samples-data/ml-engine/census/data/adult.test.csv'

    command: |
        python -m trainer.task --job-dir {job_dir} \
            --num-epochs {num_epochs} \
            --train-steps {train_steps} \
            --eval-steps {eval_steps} \
            --train-files {train_files} \
            --eval-files {eval_files} \
            --batch-size {batch_size}
