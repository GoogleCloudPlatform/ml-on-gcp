# Overview

This code implements a Logistic Regression model using the Google Cloud 
Platform and [MLflow](https://www.mlflow.org).

The sample provided uses `tf.keras`, TensorFlow's implementation of the 
Keras API specification. This provides the benefits of Keras and also 
first-class support for TensorFlow-specific functionality.
It includes code to process data, train a TensorFlow model with 
hyperparameter tuning, run predictions on new data and
assess model performance.

## **Data description**

The [Census Income Data
Set](https://archive.ics.uci.edu/ml/datasets/Census+Income) that this 
sample uses for training is hosted by the [UC Irvine Machine Learning
Repository](https://archive.ics.uci.edu/ml/datasets/).
The specific files used in this tutorial are 
[adult.data.csv](https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data)
and [adult.test.csv](https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test)
 (see below).

Using census data which contains data a person's age, education, marital 
status, and occupation (the features), we will try to predict whether or 
not the person earns more than 50,000 dollars a year (the target label). 
We will train a logistic regression model that, given an individual's 
information, outputs a number between 0 and 1, this can be interpreted 
as the probability that the individual has an annual income of over 
50,000 dollars.

As a modeler and developer, think about how this data is used and the 
potential benefits and harm a model's predictions can cause. A model 
like this could reinforce societal biases and disparities. Is each 
feature relevant to the problem you want to solve or will it introduce 
bias? For more information, read about [ML fairness](https://developers.google.com/machine-learning/fairness-overview/).

### **Disclaimer**

This dataset is provided by a third party. Google provides no 
representation, warranty, or other guarantees about the validity or any 
other aspects of this dataset.

### Create a Compute Engine instance

Create a new Deep Learning Virtual Machine (VM) instance

```
export IMAGE_FAMILY="tf-latest-cpu"
export ZONE="us-central1-b"
export INSTANCE_NAME="mlflow-server"
gcloud compute instances create $INSTANCE_NAME \
       --zone=$ZONE \
       --image-family=$IMAGE_FAMILY \
       --machine-type=n1-standard-8 \
       --image-project=deeplearning-platform-release \
       --maintenance-policy=TERMINATE \
       --scopes=https://www.googleapis.com/auth/cloud-platform \
       --tags http-server,https-server
```

#### Installing MLflow

Install git, pip and virtual environment

```
sudo apt-get install git -y
sudo apt-get install python-pip -y
pip install virtualenv
```

Create virtual environment

```
virtualenv -p `which python3` mlflow_env
source mlflow_env/bin/activate
```

Install MLflow

```
pip install mlflow
```
Verify installation

```
pip freeze | grep mlflow
mlflow==1.4.0
```

### **Install dependencies**

In this tutorial we will train a TensorFlow model and use different 
parameters. We will use MLflow to track those different parameters and 
their metrics. Start by cloning the repo.

```
git clone https://github.com/GoogleCloudPlatform/ml-on-gcp.git
cd ml-on-gcp/tutorials/tensorflow/mlflow_gcp/
```

Install the python dependencies. 

```
pip install --upgrade -r requirements.txt
```

### Run model locally (in the VM)

Define environment variables:

```
export JOB_DIR=gs://mlflow_gcp/jobs
export TRAIN_FILE=gs://cloud-samples-data/ml-engine/census/data/adult.data.csv
export EVAL_FILE=gs://cloud-samples-data/ml-engine/census/data/adult.test.csv
export TRAIN_STEPS=1000
export EVAL_STEPS=1
export BATCH_SIZE=128
```

#### Run using Python

```
python -m trainer.task \
    --train-files=$TRAIN_FILE \
    --eval-files=$EVAL_FILE \
    --job-dir=$JOB_DIR \
    --train-steps=$TRAIN_STEPS \
    --eval-steps=$EVAL_STEPS \
    --batch-size=$BATCH_SIZE \
    --num-epochs=10
```

#### Deploy model in GCP after MLflow

```
export JOB_DIR=mlflow
export TRAIN_FILE=gs://cloud-samples-data/ml-engine/census/data/adult.data.csv
export EVAL_FILE=gs://cloud-samples-data/ml-engine/census/data/adult.test.csv
export TRAIN_STEPS=1000
export EVAL_STEPS=1
export BATCH_SIZE=128
export BUCKET_NAME=<Your GCS bucket name, do not include gs://>
export PROJECT_ID=<Your Project ID>
```

Enable `deploy-gcp` flag to create a Model and a model version for 
each run.

```
python -m trainer.task \
    --train-files $TRAIN_FILE \
    --eval-files=$EVAL_FILE \
    --job-dir=$JOB_DIR \
    --train-steps=$TRAIN_STEPS \
    --eval-steps=1 \
    --batch-size=$BATCH_SIZE \
    --num-epochs=20 \
    --deploy-gcp \
    --gcs-bucket=$BUCKET_NAME \
    --project-id=$PROJECT_ID
```

This will generate a local mlruns folder where you can see the artifacts
generated by MLflow, from your terminal type:

To check the [Tracking UI](https://www.mlflow.org/docs/latest/tracking.html#tracking-ui)

```
mlflow ui --host 0.0.0.0
```

Note: the option `--host 0.0.0.0` is used to bind to all addresses if you want 
to access the tracking server (i.e. in the created VM) from other machines.
Further, the option `--port` can be used to change the port to listen on 
(default: 5000). 

If you want to access the MLflow UI from your browser directly by using the address 
`http://<MLflow Server Public IP Address>:<MLflow server port>`, you might 
set up a [firewall rule](https://cloud.google.com/vpc/docs/using-firewalls)
and a target tag allowing the access to a specific port of the tagged VMs 
from a specific range of IPs. Please note that this might cause vulnerability
issues if you don't set this rule properly.

Another, much simpler way for connecting to the MLflow UI from your browser is
through ssh port forwarding, thereby using the local address e.g. `http://localhost:5000`

```
gcloud compute ssh my-vm-name --zone=my-zone -- -NL 5000:localhost:5000
```

### Run MLFLow model

Running `mlflow run mlflow_gcp/docker` builds a new Docker image based on 
`mlflow-gcp-example` that also contains our project code. The resulting 
image is tagged as `mlflow-gcp-example-<git-version>` where `<git-version> `
is the git commit ID. After the image is built, MLflow executes the 
default (main) project entry point within the container using docker run.

Environment variables, such as `MLFLOW_TRACKING_URI`, are propagated 
inside the container during project execution. When running against a 
local tracking URI, MLflow mounts the host system's tracking directory 
(e.g., a local mlruns directory) inside the container so that metrics 
and params logged during project execution are accessible afterwards.

### Build Docker image

We create a new install based on GCP Deep Learning containers image.
You can always change it for your preferred Docker image.

### Running this example in Docker

First, install MLflow (via pip install mlflow) and install Docker.

Then, build the image for the project's Docker container environment. 
You must use the same image name that is given by the `docker_env.image` 
field of the MLproject file. In this example, the image name is mlflow-gcp-example. 
Issue the following command to build an image with this name:

```
docker build -t mlflow-gcp-example -f Dockerfile .
```

Note that the name of the image used in the docker build command, mlflow-gcp-example, 
matches the name of the image referenced in the MLproject file.

Copy `MLProject` file to project folder:

```
cd mlflow_gcp
cp docker/MLProject .
cd ..
```

Finally, run the example project using:

```
mlflow run mlflow_gcp
```
or

```
export MLFLOW_TRACKING_URI=http://<URL>:5000
export GOOGLE_APPLICATION_CREDENTIALS=/keys/key.json

mlflow run mlflow_gcp \
    -P train-files=$TRAIN_FILE \
    -P eval-files=$EVAL_FILE \
    -P job-dir=$JOB_DIR \
    -P train-steps=$TRAIN_STEPS \
    -P eval-steps=1 \
    -P batch_size=128 \
    -P num-epochs=10 
```

You will see all the runs.


#### Run locally (in the VM) via the `gcloud` command for AI Platform:

```
gcloud ai-platform local train --package-path trainer \
    --module-name trainer.task \
    -- \
    --train-files $TRAIN_FILE \
    --eval-files $EVAL_FILE \
    --job-dir $JOB_DIR \
    --train-steps $TRAIN_STEPS \
    --eval-steps $EVAL_STEPS
    --batch-size=$BATCH_SIZE \
```

#### Run via the `gcloud` command in AI Platform:

```
DATE=`date '+%Y%m%d_%H%M%S'`
export JOB_NAME=mlflow_$DATE
export REGION=us-central1
export GCS_JOB_DIR=gs://mlflow_gcp/jobs/$JOB_NAME

gcloud ai-platform jobs submit training $JOB_NAME \
   --stream-logs \
   --runtime-version 1.15 \
   --python-version 3.5 \
   --job-dir $GCS_JOB_DIR \
   --package-path trainer \
   --module-name trainer.task \
   --region $REGION \
   -- \
   --train-files $TRAIN_FILE \
   --eval-files $EVAL_FILE \
   --train-steps $TRAIN_STEPS \
   --eval-steps $EVAL_STEPS \
   --batch-size=$BATCH_SIZE \
   --mlflow-tracking-uri http://<MLflow Server Public IP Address>:<MLflow server port>
```


#### Hyperparameter tuning:

You can optionally perform hyperparameter tuning by using the included 
hptuning_config.yaml configuration file. This file tells AI Platform to 
tune the batch size and learning rate for training over multiple trials 
to maximize accuracy.

In this example, the training code uses a [TensorBoard callback](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard), 
which creates TensorFlow Summary Events during training. AI Platform uses 
these events to track the metric you want to optimize. 
Learn more about [hyperparameter tuning in AI Platform Training](https://cloud.google.com/ml-engine/docs/tensorflow/hyperparameter-tuning-overview).

## References

[Tensorflow tutorial](https://www.tensorflow.org/guide/premade_estimators)
