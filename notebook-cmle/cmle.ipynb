{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The helpers use the application default credentials.\n",
    "from cmle_utils import get_models, get_model_versions, train_model, deploy_model, set_default, predict_json, build_and_upload_package, create_package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode):\n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "    hidden = tf.layers.dense(features, 10, activation=tf.nn.relu)\n",
    "    outputs = tf.layers.dense(hidden, 1)\n",
    "\n",
    "    predictions = outputs\n",
    "    loss = None\n",
    "    train_op = None\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        loss = tf.nn.l2_loss(outputs - labels)\n",
    "\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.05)\n",
    "        train_op = optimizer.minimize(loss, global_step=global_step)\n",
    "\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        predictions=predictions,\n",
    "        loss=loss,\n",
    "        train_op=train_op\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input_fn():\n",
    "    fake_features = tf.constant([[1], [2]], dtype=tf.float32)\n",
    "    fake_labels = tf.constant([[3], [4]], dtype=tf.float32)\n",
    "    ds = tf.data.Dataset.from_tensor_slices(\n",
    "        (fake_features, fake_labels)\n",
    "    )\n",
    "    return ds.repeat().batch(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        '--job-dir',\n",
    "        default='/tmp/cmle'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--steps',\n",
    "        default=300)\n",
    "\n",
    "    args, unused_args = parser.parse_known_args()\n",
    "    \n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args):\n",
    "    estimator = tf.estimator.Estimator(model_fn, model_dir=args.job_dir)\n",
    "    estimator.train(train_input_fn, steps=args.steps)\n",
    "    \n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parse_args()\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = estimator.predict(input_fn=train_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(next(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run on CMLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execfile('cmle_utils.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_package(model_fn, train_input_fn, parse_args, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# package and upload to gcs before we can train\n",
    "# this requires having a setup.py in the directory\n",
    "# this needs to be rerun everytime the trainer model is updated and right before calling train_model\n",
    "\n",
    "package_path = build_and_upload_package('gs://.../package')\n",
    "\n",
    "# this is needed in the job_spec\n",
    "print(package_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train in the cloud\n",
    "import time\n",
    "import os\n",
    "\n",
    "BUCKET = 'gs://.../test'\n",
    "JOB_DIR = os.path.join(BUCKET, 'output')\n",
    "\n",
    "training_inputs = {\n",
    "    'scaleTier': 'BASIC',\n",
    "    'packageUris': [package_path],\n",
    "    'pythonModule': 'trainer.task',\n",
    "    'region': 'us-central1',\n",
    "    'jobDir': JOB_DIR,\n",
    "    'runtimeVersion': '1.8',\n",
    "    'args': [\n",
    "        '--steps 1000'\n",
    "    ]\n",
    "}\n",
    "job_spec = {'jobId': 'test_' + str(int(time.time())), 'trainingInput': training_inputs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = ...\n",
    "train_model(PROJECT_ID, job_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
